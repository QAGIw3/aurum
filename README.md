# Aurum

Aurum is a comprehensive market intelligence platform for energy trading, providing curve data, scenario modeling, and external data ingestion capabilities.

## Quick Start

1. **Setup**: Copy `.env.example` to `.env` and populate required secrets
2. **Start Platform**: `COMPOSE_PROFILES=core docker compose -f compose/docker-compose.dev.yml up -d`
3. **Bootstrap**: `COMPOSE_PROFILES=core,bootstrap docker compose -f compose/docker-compose.dev.yml up bootstrap --exit-code-from bootstrap`
4. **Access Services**: 
   - API: `http://localhost:8095`
   - Airflow: `http://localhost:8088`
   - MinIO: `http://localhost:9001`
   - Trino: `http://localhost:8080`

## Documentation

ğŸ“– **[Complete Documentation â†’](docs/README.md)**

### Essential Links
- ğŸš€ [Onboarding Guide](docs/onboarding.md) - Get started quickly
- ğŸ—ï¸ [Architecture Overview](docs/architecture-overview.md) - System design
- ğŸ“š [API Documentation](docs/api/README.md) - API usage and examples
- â˜¸ï¸ [Kubernetes Development](docs/k8s-dev.md) - K8s workflow
- ğŸ”’ [Security & Auth](docs/security/tenant-rls.md) - Authentication setup
- ï¿½ï¿½ [Runbooks](docs/runbooks/) - Operations guides
- ğŸ’¡ [Contributing](CONTRIBUTING.md) - Development guidelines

## Repository Structure

```
aurum/
â”œâ”€â”€ airflow/          # Airflow DAGs for data orchestration
â”œâ”€â”€ dbt/              # dbt models for data transformation
â”œâ”€â”€ docs/             # Documentation (architecture, guides, runbooks)
â”œâ”€â”€ kafka/schemas/    # Avro schemas for Kafka topics
â”œâ”€â”€ src/aurum/        # Core application code
â”‚   â”œâ”€â”€ api/          # FastAPI web service
â”‚   â”œâ”€â”€ scenarios/    # Scenario modeling engine
â”‚   â”œâ”€â”€ parsers/      # Vendor data parsers
â”‚   â””â”€â”€ external/     # External data collectors
â”œâ”€â”€ trino/ddl/        # Iceberg table definitions
â”œâ”€â”€ k8s/              # Kubernetes manifests
â””â”€â”€ scripts/          # Utility scripts and tools
```

## Key Features

- **ğŸ”„ Data Ingestion**: Automated pipelines for EIA, NOAA, FRED, and ISO data
- **ğŸ“Š Curve Analytics**: Market curve analysis and forecasting
- **ğŸ¯ Scenario Modeling**: What-if analysis and scenario planning
- **ğŸ”Œ REST API**: Comprehensive API for data access and management
- **âš¡ Real-time Processing**: Kafka-based streaming architecture
- **ğŸ—„ï¸ Multi-store Architecture**: Trino, TimescaleDB, ClickHouse backends

## API Examples

```bash
# Get curve data
curl "http://localhost:8095/v1/curves?iso=PJM&market=DA&limit=10"

# List scenarios
curl "http://localhost:8095/v1/scenarios?limit=20"

# Create scenario
curl -X POST "http://localhost:8095/v1/scenarios" \
  -H "Content-Type: application/json" \
  -d '{"name": "Test Scenario", "assumptions": [...]}'
```

## Development

### Local Development
```bash
# Install dependencies
pip install -e .

# Start core services
COMPOSE_PROFILES=core docker compose -f compose/docker-compose.dev.yml up -d

# Run tests
pytest tests/

# Lint code
make lint
```

### Kubernetes Development
See [K8s Development Guide](docs/k8s-dev.md) for complete instructions on:
- Setting up kind clusters
- Deploying to Kubernetes
- Managing secrets and configuration

## Support

- ğŸ“– [Documentation](docs/README.md) - Complete guides and references
- ğŸ› [Issues](https://github.com/QAGIw3/aurum/issues) - Bug reports and feature requests
- ğŸ’¬ [Discussions](https://github.com/QAGIw3/aurum/discussions) - Questions and community
