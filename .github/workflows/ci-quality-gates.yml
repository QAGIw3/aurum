name: CI Quality Gates

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'requirements*.txt'
      - '.github/workflows/ci-quality-gates.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'requirements*.txt'
      - '.github/workflows/ci-quality-gates.yml'

env:
  PYTHON_VERSION: "3.11"
  POETRY_VERSION: "1.7.1"

jobs:
  # Fast feedback for basic syntax and import checks
  pre-commit:
    name: Pre-commit Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pre-commit
        uses: actions/cache@v3
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-

      - name: Install pre-commit
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit

      - name: Run pre-commit
        run: pre-commit run --all-files --show-diff-on-failure

  # Python type checking
  type-check:
    name: Type Checking (mypy)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mypy types-all

      - name: Run mypy
        run: |
          mypy src/ --ignore-missing-imports --no-strict-optional --warn-redundant-casts --warn-unused-ignores --warn-return-any --warn-unused-configs --warn-unreachable

  # Code formatting and linting
  lint:
    name: Code Quality (ruff)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install ruff
        run: |
          python -m pip install --upgrade pip
          pip install ruff

      - name: Run ruff format check
        run: ruff format --check --diff src/ tests/

      - name: Run ruff lint
        run: |
          ruff check src/ tests/ --select=E9,F63,F7,F82 --show-source
          ruff check src/ tests/ --select=E,W --ignore=E501,W503 --show-source

  # Comprehensive test suite
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]
        test-type: ["unit", "integration", "property"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[test]
          pip install pytest pytest-asyncio pytest-cov pytest-mock hypothesis

      - name: Run unit tests
        if: matrix.test-type == 'unit'
        run: |
          pytest tests/ \
            --cov=src/aurum \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=80 \
            -v

      - name: Run integration tests
        if: matrix.test-type == 'integration'
        run: |
          pytest tests/api/ \
            --cov=src/aurum \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-append \
            -v

      - name: Run property-based tests
        if: matrix.test-type == 'property'
        run: |
          pytest tests/api/test_scenario_models_property.py \
            --cov=src/aurum \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-append \
            -v

      - name: Upload coverage reports
        if: matrix.test-type == 'unit'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: python-${{ matrix.python-version }}
          name: codecov-umbrella
          fail_ci_if_error: false

  # Security scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    permissions:
      security-events: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety

      - name: Run bandit security linter
        run: |
          bandit -r src/ -f json -o bandit-report.json || true
          bandit -r src/ -f sarif -o bandit-report.sarif || true

      - name: Run safety check
        run: |
          safety check --json > safety-report.json || true

      - name: Upload security scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: bandit-report.sarif
        if: always()

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
          retention-days: 30

  # OpenAPI specification validation
  openapi-spec:
    name: OpenAPI Specification
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fastapi openapi-spec-validator

      - name: Generate OpenAPI spec
        run: |
          python -c "
          from aurum.api.app import create_app
          from aurum.core import AurumSettings
          import json

          settings = AurumSettings()
          app = create_app(settings)

          # Generate OpenAPI spec
          openapi_spec = app.openapi()
          with open('openapi-spec.json', 'w') as f:
              json.dump(openapi_spec, f, indent=2)

          print('OpenAPI specification generated')
          "

      - name: Validate OpenAPI spec
        run: |
          python -c "
          from openapi_spec_validator import validate_spec
          import json

          with open('openapi-spec.json', 'r') as f:
              spec = json.load(f)

          try:
              validate_spec(spec)
              print('✅ OpenAPI specification is valid')
          except Exception as e:
              print(f'❌ OpenAPI validation failed: {e}')
              exit(1)
          "

      - name: Compare OpenAPI spec (PR only)
        if: github.event_name == 'pull_request'
        run: |
          # Fetch base branch spec
          git fetch origin ${{ github.base_ref }}
          git checkout ${{ github.base_ref }} -- openapi-spec.json || true

          if [ -f openapi-spec.json ]; then
            python -c "
            import json
            import sys

            # Load specs
            with open('openapi-spec.json', 'r') as f:
                base_spec = json.load(f)

            with open('openapi-spec-new.json', 'w') as f:
                f.write(open('openapi-spec.json', 'r').read())

            # Simple comparison (could be enhanced)
            base_version = base_spec.get('info', {}).get('version', 'unknown')
            new_version = json.load(open('openapi-spec.json')).get('info', {}).get('version', 'unknown')

            print(f'Base API version: {base_version}')
            print(f'New API version: {new_version}')

            if base_version != new_version:
              print('⚠️ API version changed - review breaking changes')
            else:
              print('✅ API version unchanged')
            "
          else:
            echo "No base spec found for comparison"
          fi

      - name: Upload OpenAPI spec
        uses: actions/upload-artifact@v4
        with:
          name: openapi-spec
          path: openapi-spec.json
          retention-days: 30

  # Dependency vulnerability scanning
  dependency-scan:
    name: Dependency Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pip-audit

      - name: Run pip-audit
        run: |
          pip-audit --format=json > pip-audit-report.json || true

      - name: Upload dependency scan results
        uses: actions/upload-artifact@v4
        with:
          name: dependency-scan
          path: pip-audit-report.json
          retention-days: 30

  # Performance regression testing
  performance-test:
    name: Performance Regression Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest-benchmark

      - name: Run performance benchmarks
        run: |
          pytest tests/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-compare-fail=regression:5% \
            --benchmark-compare=origin/main

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: performance-benchmarks
          path: benchmark-results.json
          retention-days: 30

  # Quality gate summary
  quality-gate:
    name: Quality Gate Summary
    runs-on: ubuntu-latest
    needs: [pre-commit, type-check, lint, test, security-scan, openapi-spec, dependency-scan]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get job results
        run: |
          echo "## 📊 Quality Gate Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check individual job results
          if [ "${{ needs.pre-commit.result }}" == "success" ]; then
            echo "✅ **Pre-commit Checks**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Pre-commit Checks**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.type-check.result }}" == "success" ]; then
            echo "✅ **Type Checking**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Type Checking**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.lint.result }}" == "success" ]; then
            echo "✅ **Code Quality**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Code Quality**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.test.result }}" == "success" ]; then
            echo "✅ **Test Suite**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Test Suite**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.security-scan.result }}" == "success" ]; then
            echo "✅ **Security Scanning**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ **Security Scanning**: Completed (review reports)" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.openapi-spec.result }}" == "success" ]; then
            echo "✅ **OpenAPI Specification**: Valid" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **OpenAPI Specification**: Invalid" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.dependency-scan.result }}" == "success" ]; then
            echo "✅ **Dependency Scanning**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ **Dependency Scanning**: Completed (review reports)" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY

          # Overall status
          if [ "${{ needs.test.result }}" == "success" ] && \
             [ "${{ needs.type-check.result }}" == "success" ] && \
             [ "${{ needs.lint.result }}" == "success" ] && \
             [ "${{ needs.openapi-spec.result }}" == "success" ]; then
            echo "## 🎉 **All Quality Gates Passed!**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The code meets all quality standards and is ready for review." >> $GITHUB_STEP_SUMMARY
          else
            echo "## ⚠️ **Quality Gates Require Attention**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Please address the failing checks before merging." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Set PR status
        if: github.event_name == 'pull_request'
        run: |
          if [ "${{ needs.test.result }}" == "success" ] && \
             [ "${{ needs.type-check.result }}" == "success" ] && \
             [ "${{ needs.lint.result }}" == "success" ] && \
             [ "${{ needs.openapi-spec.result }}" == "success" ]; then
            echo "✅ Quality gates passed"
          else
            echo "❌ Quality gates failed"
            exit 1
          fi
