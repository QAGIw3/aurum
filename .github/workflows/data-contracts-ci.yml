name: Data Contracts and Quality Gates

on:
  push:
    branches: [main, develop]
    paths:
      - 'dbt/**'
      - 'ge/**'
      - 'kafka/schemas/**'
      - 'scripts/data_contracts/**'
      - 'tests/kafka/**'
  pull_request:
    branches: [main, develop]
    paths:
      - 'dbt/**'
      - 'ge/**'
      - 'kafka/schemas/**'
      - 'scripts/data_contracts/**'
      - 'tests/kafka/**'
  workflow_dispatch:
    inputs:
      enforce_contracts:
        description: 'Enforce data contracts (fail on violations)'
        required: false
        default: true
        type: boolean
      run_quality_checks:
        description: 'Run data quality checks'
        required: false
        default: true
        type: boolean

env:
  DBT_PROFILES_DIR: ${{ github.workspace }}/tests/dbt
  DBT_TARGET: duckdb
  DBT_VARS: '{"iceberg_catalog": "main"}'

jobs:
  dbt-compile-test:
    name: dbt Compile and Test
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Prepare dbt artifacts directory
      run: |
        mkdir -p artifacts/dbt

    - name: dbt dependencies
      run: |
        dbt deps --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS"

    - name: dbt compile (all models)
      run: |
        dbt compile --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS"

    - name: dbt test (all tests)
      run: |
        dbt test --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS"

    - name: dbt build (stg layer)
      run: |
        dbt build --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS" -m stg

    - name: dbt build (int layer)
      run: |
        dbt build --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS" -m int

    - name: dbt build (marts layer)
      run: |
        dbt build --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS" -m marts

    - name: dbt docs generate
      run: |
        dbt docs generate --profiles-dir "$DBT_PROFILES_DIR" --target "$DBT_TARGET" --vars "$DBT_VARS"

    - name: Upload dbt docs
      uses: actions/upload-artifact@v4
      with:
        name: dbt-docs-${{ github.sha }}
        path: artifacts/dbt

  great-expectations-quality:
    name: Great Expectations Quality Gates
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Prepare test data directory
      run: |
        mkdir -p testdata/ge

    - name: Run Great Expectations suites
      run: |
        python scripts/quality/run_ge_checks.py --data-dir testdata/ge --report-dir ge-reports

    - name: Validate data contracts
      run: |
        python scripts/data_contracts/validate_contracts.py --ge-expectations ge/expectations --report-dir contract-reports

    - name: Check data quality thresholds
      run: |
        python scripts/data_contracts/check_quality_thresholds.py --ge-reports ge-reports --threshold-file scripts/data_contracts/quality_thresholds.json

    - name: Upload GE reports
      uses: actions/upload-artifact@v4
      with:
        name: great-expectations-reports-${{ github.sha }}
        path: |
          ge-reports/
          contract-reports/

    - name: Generate quality summary
      run: |
        python scripts/data_contracts/generate_quality_summary.py --ge-reports ge-reports --output quality-summary.json

    - name: Upload quality summary
      uses: actions/upload-artifact@v4
      with:
        name: data-quality-summary-${{ github.sha }}
        path: quality-summary.json

  kafka-contract-tests:
    name: Kafka Consumer-Driven Contracts
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Set up Kafka test environment
      run: |
        docker run -d --name kafka-test -p 9092:9092 -p 9093:9093 \
          -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
          -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
          confluentinc/cp-kafka:7.4.0

        # Wait for Kafka to be ready
        timeout 60 bash -c 'until nc -z localhost 9092; do sleep 1; done'

    - name: Set up Schema Registry
      run: |
        docker run -d --name schema-registry-test -p 8081:8081 \
          -e SCHEMA_REGISTRY_HOST_NAME=schema-registry \
          -e SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=localhost:9092 \
          confluentinc/cp-schema-registry:7.4.0

        # Wait for Schema Registry to be ready
        timeout 60 bash -c 'until nc -z localhost 8081; do sleep 1; done'

    - name: Run consumer-driven contract tests
      run: |
        python scripts/data_contracts/run_pact_tests.py \
          --kafka-bootstrap localhost:9092 \
          --schema-registry http://localhost:8081 \
          --contracts-dir tests/kafka/contracts \
          --report-dir pact-reports

    - name: Validate contract compatibility
      run: |
        python scripts/data_contracts/validate_contract_compatibility.py \
          --contracts-dir tests/kafka/contracts \
          --schemas-dir kafka/schemas \
          --report-dir compatibility-reports

    - name: Upload contract test reports
      uses: actions/upload-artifact@v4
      with:
        name: kafka-contract-reports-${{ github.sha }}
        path: |
          pact-reports/
          compatibility-reports/

  data-lineage-validation:
    name: Data Lineage and Schema Validation
    runs-on: ubuntu-latest
    needs: [dbt-compile-test, great-expectations-quality]
    if: github.event_name == 'pull_request' && github.event.inputs.enforce_contracts != 'false'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download dbt artifacts
      uses: actions/download-artifact@v4
      with:
        name: dbt-docs-${{ github.sha }}
        path: artifacts/dbt

    - name: Download GE reports
      uses: actions/download-artifact@v4
      with:
        name: great-expectations-reports-${{ github.sha }}
        path: ge-reports

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Validate data lineage
      run: |
        python scripts/data_contracts/validate_lineage.py \
          --dbt-manifest artifacts/dbt/manifest.json \
          --dbt-run-results artifacts/dbt/run_results.json \
          --lineage-output lineage-report.json

    - name: Check schema evolution
      run: |
        python scripts/data_contracts/check_schema_evolution.py \
          --current-schemas kafka/schemas \
          --lineage-report lineage-report.json \
          --evolution-report schema-evolution.json

    - name: Validate data contracts
      run: |
        python scripts/data_contracts/enforce_contracts.py \
          --ge-reports ge-reports \
          --lineage-report lineage-report.json \
          --schema-evolution schema-evolution.json \
          --fail-on-violations ${{ github.event.inputs.enforce_contracts == 'true' || github.event.inputs.enforce_contracts == null }}

    - name: Upload lineage reports
      uses: actions/upload-artifact@v4
      with:
        name: data-lineage-reports-${{ github.sha }}
        path: |
          lineage-report.json
          schema-evolution.json

  alert-routing-validation:
    name: Alert Routing Validation
    runs-on: ubuntu-latest
    needs: [great-expectations-quality, kafka-contract-tests]
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download GE reports
      uses: actions/download-artifact@v4
      with:
        name: great-expectations-reports-${{ github.sha }}
        path: ge-reports

    - name: Download contract reports
      uses: actions/download-artifact@v4
      with:
        name: kafka-contract-reports-${{ github.sha }}
        path: contract-reports

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt

    - name: Validate alert routing rules
      run: |
        python scripts/data_contracts/validate_alert_routing.py \
          --ge-reports ge-reports \
          --contract-reports contract-reports \
          --alert-config alerts/routing-config.json \
          --validation-report alert-routing-validation.json

    - name: Test alert scenarios
      run: |
        python scripts/data_contracts/test_alert_scenarios.py \
          --scenarios alerts/test-scenarios.json \
          --routing-config alerts/routing-config.json \
          --test-results alert-scenario-tests.json

    - name: Upload alert validation reports
      uses: actions/upload-artifact@v4
      with:
        name: alert-validation-reports-${{ github.sha }}
        path: |
          alert-routing-validation.json
          alert-scenario-tests.json

  notify-on-data-quality-issues:
    name: Notify on Data Quality Issues
    runs-on: ubuntu-latest
    needs: [great-expectations-quality, kafka-contract-tests]
    if: failure() && github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download GE reports
      uses: actions/download-artifact@v4
      with:
        name: great-expectations-reports-${{ github.sha }}
        path: ge-reports

    - name: Download contract reports
      uses: actions/download-artifact@v4
      with:
        name: kafka-contract-reports-${{ github.sha }}
        path: contract-reports

    - name: Analyze quality failures
      run: |
        python scripts/data_contracts/analyze_quality_failures.py \
          --ge-reports ge-reports \
          --contract-reports contract-reports \
          --failure-analysis failure-analysis.json

    - name: Notify team of data quality issues
      run: |
        echo "ðŸš¨ Data Quality Issues Detected in Main Branch" > notification-message.txt
        echo "" >> notification-message.txt
        echo "Issues found in:" >> notification-message.txt
        if [ -f ge-reports/failed-expectations.json ]; then
          echo "- Great Expectations validations" >> notification-message.txt
        fi
        if [ -f contract-reports/contract-violations.json ]; then
          echo "- Kafka contract violations" >> notification-message.txt
        fi
        echo "" >> notification-message.txt
        echo "See detailed reports for more information." >> notification-message-message.txt

        # This would integrate with Slack, Teams, or other notification systems
        if [ -n "$SLACK_WEBHOOK_URL" ]; then
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"ðŸš¨ Data Quality Issues Detected - Manual review required"}' \
            $SLACK_WEBHOOK_URL
        fi
