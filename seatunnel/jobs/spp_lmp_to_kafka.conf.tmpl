# SPP staged JSON â†’ Kafka (Avro)
#
# Required environment variables:
#   SPP_INPUT_JSON          - Path to JSON file containing normalized SPP LMP records (array of objects)
#   KAFKA_BOOTSTRAP_SERVERS - Kafka brokers
#   SCHEMA_REGISTRY_URL     - Schema Registry endpoint
#
# Optional environment variables:
#   SPP_TOPIC               - Kafka topic (default aurum.iso.spp.lmp.v1)
#   SPP_SUBJECT             - Schema Registry subject (default <topic>-value)
#   ISO_LMP_SCHEMA          - Avro schema JSON populated by run_job.sh
#   SPP_CURRENCY            - Override currency code (default USD)
#   SPP_UOM                 - Override unit of measure (default MWh)
#   ISO_LOCATION_REGISTRY   - Path to iso_nodes.csv (default config/iso_nodes.csv)

env {
  job.mode = "BATCH"
  parallelism = 1
}

source {
  LocalFile {
    path = "${SPP_INPUT_JSON}"
    format = "json"
    schema {
      fields {
        market = string
        delivery_date = string
        interval_start = string
        interval_end = string
        interval_minutes = string
        location_id = string
        location_name = string
        location_type = string
        price_total = string
        price_energy = string
        price_congestion = string
        price_loss = string
        currency = string
        uom = string
        settlement_point = string
        source_run_id = string
        ingest_ts = string
        record_hash = string
      }
    }
    jsonpath = "$$[*]"
    result_table_name = "spp_stage"
  }
  LocalFile {
    path = "${ISO_LOCATION_REGISTRY}"
    format = "csv"
    csv {
      delimiter = ","
      header = true
    }
    schema {
      fields {
        iso = string
        location_id = string
        location_name = string
        location_type = string
        zone = string
        hub = string
        timezone = string
      }
    }
    result_table_name = "iso_registry"
  }
}

transform {
  Sql {
    source_table_name = "spp_stage"
    result_table_name = "spp_normalized"
    query = """
      SELECT
        'SPP' AS iso_code,
        CASE
          WHEN upper(CAST(s.market AS STRING)) IN ('DA', 'DAM', 'DAY_AHEAD') THEN 'DAY_AHEAD'
          WHEN upper(CAST(s.market AS STRING)) IN ('RT', 'RTM', 'REAL_TIME') THEN 'REAL_TIME'
          ELSE COALESCE(UPPER(CAST(s.market AS STRING)), 'UNKNOWN')
        END AS market,
        CAST(s.delivery_date AS INT) AS delivery_date,
        CAST(s.interval_start AS BIGINT) AS interval_start,
        CASE
          WHEN s.interval_end IS NULL OR CAST(s.interval_end AS BIGINT) = 0 THEN NULL
          ELSE CAST(s.interval_end AS BIGINT)
        END AS interval_end,
        CAST(s.interval_minutes AS INT) AS interval_minutes,
        CAST(s.location_id AS STRING) AS location_id,
        COALESCE(reg.location_name, CAST(s.location_name AS STRING)) AS location_name,
        COALESCE(reg.location_type, COALESCE(UPPER(CAST(s.location_type AS STRING)), 'NODE')) AS location_type,
        reg.zone AS zone,
        reg.hub AS hub,
        reg.timezone AS timezone,
        CAST(s.price_total AS DOUBLE) AS price_total,
        CAST(s.price_energy AS DOUBLE) AS price_energy,
        CAST(s.price_congestion AS DOUBLE) AS price_congestion,
        CAST(s.price_loss AS DOUBLE) AS price_loss,
        COALESCE(CAST(s.currency AS STRING), '${SPP_CURRENCY}') AS currency,
        COALESCE(CAST(s.uom AS STRING), '${SPP_UOM}') AS uom,
        CAST(s.settlement_point AS STRING) AS settlement_point,
        CAST(s.source_run_id AS STRING) AS source_run_id,
        COALESCE(CAST(s.ingest_ts AS BIGINT), CAST(UNIX_TIMESTAMP() * 1000000 AS BIGINT)) AS ingest_ts,
        CAST(s.record_hash AS STRING) AS record_hash,
        NULL AS metadata
      FROM spp_stage s
      LEFT JOIN iso_registry reg
        ON upper(reg.iso) = 'SPP'
       AND upper(reg.location_id) = upper(CAST(s.location_id AS STRING))
    """
  }
}

sink {
  Kafka {
    plugin_input = "spp_normalized"
    bootstrap.servers = "${KAFKA_BOOTSTRAP_SERVERS}"
    topic = "${SPP_TOPIC}"
    semantic = "AT_LEAST_ONCE"
    format = "avro"
    avro {
      use.schema.registry = true
      schema.registry.url = "${SCHEMA_REGISTRY_URL}"
      value.schema.subject = "${SPP_SUBJECT}"
      value.schema = """${ISO_LMP_SCHEMA}"""
    }
    producer {
      linger.ms = 500
      batch.size = 32768
      retries = 5
    }
  }
}
