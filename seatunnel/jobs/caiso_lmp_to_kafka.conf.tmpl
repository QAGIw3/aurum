# CAISO staged JSON â†’ Kafka (Avro)
#
# Required environment variables:
#   CAISO_INPUT_JSON        - Path to JSON file containing normalized CAISO LMP records (array of objects)
#   KAFKA_BOOTSTRAP_SERVERS - Kafka brokers
#   SCHEMA_REGISTRY_URL     - Schema Registry endpoint
#
# Optional environment variables:
#   CAISO_TOPIC             - Kafka topic (default aurum.iso.caiso.lmp.v1)
#   CAISO_SUBJECT           - Schema Registry subject (default <topic>-value)
#   ISO_LMP_SCHEMA          - Avro schema JSON populated by run_job.sh
#   CAISO_CURRENCY          - Override currency code (default USD)
#   CAISO_UOM               - Override unit of measure (default MWh)
#   ISO_LOCATION_REGISTRY   - Path to iso_nodes.csv (default config/iso_nodes.csv)

env {
  job.mode = "BATCH"
  parallelism = 1
}

source {
  LocalFile {
    path = "${CAISO_INPUT_JSON}"
    format = "json"
    json {
      json_path = "$$[*]"
    }
    result_table_name = "caiso_stage"
  }
  LocalFile {
    path = "${ISO_LOCATION_REGISTRY}"
    format = "csv"
    csv {
      delimiter = ","
      header = true
    }
    schema {
      fields {
        iso = string
        location_id = string
        location_name = string
        location_type = string
        zone = string
        hub = string
        timezone = string
      }
    }
    result_table_name = "iso_registry"
  }
}

transform {
  Sql {
    source_table_name = "caiso_stage"
    result_table_name = "caiso_normalized"
    query = """
      SELECT
        'CAISO' AS iso_code,
        CASE
          WHEN upper(CAST(s.market AS STRING)) IN ('DA', 'DAY_AHEAD') THEN 'DAY_AHEAD'
          WHEN upper(CAST(s.market AS STRING)) IN ('RT', 'RTM', 'REAL_TIME', 'RTPD') THEN 'REAL_TIME'
          WHEN upper(CAST(s.market AS STRING)) IN ('FMM', 'FIFTEEN_MINUTE') THEN 'FIFTEEN_MINUTE'
          ELSE COALESCE(UPPER(CAST(s.market AS STRING)), 'UNKNOWN')
        END AS market,
        CAST(s.delivery_date AS INT) AS delivery_date,
        CAST(s.interval_start AS BIGINT) AS interval_start,
        CASE
          WHEN s.interval_end IS NULL OR CAST(s.interval_end AS BIGINT) = 0 THEN NULL
          ELSE CAST(s.interval_end AS BIGINT)
        END AS interval_end,
        CAST(s.interval_minutes AS INT) AS interval_minutes,
        CAST(s.location_id AS STRING) AS location_id,
        COALESCE(r.location_name, CAST(s.location_name AS STRING)) AS location_name,
        COALESCE(r.location_type, COALESCE(UPPER(CAST(s.location_type AS STRING)), 'NODE')) AS location_type,
        r.zone AS zone,
        r.hub AS hub,
        r.timezone AS timezone,
        CAST(s.price_total AS DOUBLE) AS price_total,
        CAST(s.price_energy AS DOUBLE) AS price_energy,
        CAST(s.price_congestion AS DOUBLE) AS price_congestion,
        CAST(s.price_loss AS DOUBLE) AS price_loss,
        COALESCE(CAST(s.currency AS STRING), '${CAISO_CURRENCY}') AS currency,
        COALESCE(CAST(s.uom AS STRING), '${CAISO_UOM}') AS uom,
        CAST(s.settlement_point AS STRING) AS settlement_point,
        CAST(s.source_run_id AS STRING) AS source_run_id,
        COALESCE(CAST(s.ingest_ts AS BIGINT), CAST(UNIX_TIMESTAMP() * 1000000 AS BIGINT)) AS ingest_ts,
        CAST(s.record_hash AS STRING) AS record_hash,
        CASE
          WHEN s.metadata IS NULL THEN NULL
          ELSE CAST(s.metadata AS MAP<STRING, STRING>)
        END AS metadata
      FROM caiso_stage s
      LEFT JOIN iso_registry r
        ON upper(r.iso) = 'CAISO'
       AND upper(r.location_id) = upper(CAST(s.location_id AS STRING))
    """
  }
}

sink {
  Kafka {
    bootstrap.servers = "${KAFKA_BOOTSTRAP_SERVERS}"
    topic = "${CAISO_TOPIC}"
    semantic = "AT_LEAST_ONCE"
    format = "avro"
    avro {
      use.schema.registry = true
      schema.registry.url = "${SCHEMA_REGISTRY_URL}"
      value.schema.subject = "${CAISO_SUBJECT}"
      value.schema = """${ISO_LMP_SCHEMA}"""
    }
    producer {
      linger.ms = 500
      batch.size = 32768
      retries = 5
    }
  }
}
