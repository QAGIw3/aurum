# Drought index topic â†’ Iceberg (environment.drought_index)
#
# Required environment variables:
#   KAFKA_BOOTSTRAP_SERVERS    - Kafka brokers
#   SCHEMA_REGISTRY_URL        - Schema Registry endpoint
#   ICEBERG_CATALOG_NAME       - Iceberg catalog name (e.g. nessie)
#   ICEBERG_CATALOG_TYPE       - Catalog type (nessie, hive, rest)
#   ICEBERG_URI                - Catalog endpoint / Hive metastore URI
#   ICEBERG_WAREHOUSE          - Warehouse path
#   ICEBERG_DB                 - Database/schema (default environment)
#   ICEBERG_TABLE              - Table name (default drought_index)
#
# Optional environment variables:
#   DROUGHT_INDEX_TOPIC_PATTERN- Regex pattern for topics (default aurum\.drought\.index\.v1)
#   ICEBERG_WRITE_DISTRIBUTION - Write distribution mode (hash)
#   ICEBERG_WRITE_FORMAT       - File format (parquet)
#   ICEBERG_PRIMARY_KEYS       - Primary key columns (series_id,region_type,valid_date)

env {
  job.mode = "STREAMING"
  checkpoint.interval = 60000
}

source {
  Kafka {
    bootstrap.servers = "${KAFKA_BOOTSTRAP_SERVERS}"
    topic = "aurum.drought.index.v1"
    format = "avro"
    start_mode = "latest"
    avro {
      schema.registry.url = "${SCHEMA_REGISTRY_URL}"
    }
    result_table_name = "drought_index_raw"
  }
}

transform {
  Sql {
    source_table_name = "drought_index_raw"
    result_table_name = "drought_index_enriched"
    query = """
      SELECT
        tenant_id,
        schema_version,
        TO_TIMESTAMP(ingest_ts / 1000000.0)         AS ingest_ts,
        ingest_job_id,
        series_id,
        region_type,
        region_id,
        dataset,
        index,
        timescale,
        (DATE '1970-01-01' + valid_date * INTERVAL '1' DAY) AS valid_date,
        CASE WHEN as_of IS NOT NULL THEN TO_TIMESTAMP(as_of / 1000000.0) ELSE NULL END AS as_of,
        value,
        unit,
        poc,
        source_url,
        CAST(metadata AS STRING) AS metadata
      FROM drought_index_raw
    """
  }
}

sink {
  Iceberg {
    plugin_input = "drought_index_enriched"
    catalog_name = "${ICEBERG_CATALOG_NAME}"
    catalog_type = "${ICEBERG_CATALOG_TYPE}"
    uri = "${ICEBERG_URI}"
    warehouse = "${ICEBERG_WAREHOUSE}"
    database = "environment"
    table = "drought_index"
    write.distribution-mode = "hash"
    format = "parquet"
    primary_keys = ["series_id", "region_type", "valid_date"]
    upsert = true
  }
}

