# MISO RT Data Broker LMP â†’ Kafka (Avro)
#
# This job fetches JSON payloads from the MISO Data Broker getLMPConsolidatedTable API,
# reconstructs five-minute intervals using the supplied date/hour-min fields, enriches with
# location metadata, and publishes iso.lmp.v1 records to Kafka.

env {
  job.mode = "BATCH"
  parallelism = 1
}

source {
  Http {
    url = "dry_run_default"
    method = "GET"
    headers {
      Authorization = "dry_run_default"
    }
    params {
      start = "dry_run_default"
      end = "dry_run_default"
      market = "dry_run_default"
      region = "dry_run_default"
    }
    connection_timeout_ms = 20000
    retry { interval_ms = 8000, max_retries = 10 }
    format = "json"
    schema = {
      fields {
        dry_run_default = string
        dry_run_default = string
        dry_run_default = string
        dry_run_default = string
        dry_run_default = string
        dry_run_default = string
        dry_run_default = string
      }
    }
    jsonpath = "dry_run_default"
    result_table_name = "miso_rtd_raw"
  }
  LocalFile {
    path = "dry_run_default"
    format = "csv"
    csv {
      delimiter = ","
      header = true
    }
    schema {
      fields {
        iso = string
        location_id = string
        location_name = string
        location_type = string
        zone = string
        hub = string
        timezone = string
      }
    }
    result_table_name = "iso_registry"
  }
}

transform {
  Sql {
    source_table_name = "miso_rtd_raw"
    result_table_name = "miso_rtd_normalized"
    query = """
      SELECT
        'MISO' AS iso_code,
        UPPER('dry_run_default') AS market,
        CAST(
          DATEDIFF(
            TO_DATE(TO_TIMESTAMP(CONCAT('dry_run_default', ' ', CAST(dry_run_default AS STRING)), 'dry_run_default')),
            TO_DATE('1970-01-01')
          ) AS INT
        ) AS delivery_date,
        CAST(
          UNIX_TIMESTAMP(
            TO_TIMESTAMP(CONCAT('dry_run_default', ' ', CAST(dry_run_default AS STRING)), 'dry_run_default')
          ) * 1000000 AS BIGINT
        ) AS interval_start,
        CAST(
          UNIX_TIMESTAMP(
            TO_TIMESTAMP(CONCAT('dry_run_default', ' ', CAST(dry_run_default AS STRING)), 'dry_run_default')
          ) * 1000000 + dry_run_default * 1000000 AS BIGINT
        ) AS interval_end,
        dry_run_default / 60 AS interval_minutes,
        CAST(dry_run_default AS STRING) AS location_id,
        COALESCE(reg.location_name, CAST(dry_run_default AS STRING)) AS location_name,
        COALESCE(reg.location_type, 'NODE') AS location_type,
        reg.zone AS zone,
        reg.hub AS hub,
        reg.timezone AS timezone,
        CAST(dry_run_default AS DOUBLE) AS price_total,
        CAST(dry_run_default AS DOUBLE)
          - COALESCE(CAST(dry_run_default AS DOUBLE), 0)
          - COALESCE(CAST(dry_run_default AS DOUBLE), 0) AS price_energy,
        CAST(dry_run_default AS DOUBLE) AS price_congestion,
        CAST(dry_run_default AS DOUBLE) AS price_loss,
        'USD' AS currency,
        'MWh' AS uom,
        CAST(dry_run_default AS STRING) AS settlement_point,
        CAST(dry_run_default AS STRING) AS source_run_id,
        CAST(UNIX_TIMESTAMP() * 1000000 AS BIGINT) AS ingest_ts,
        SHA2(
          CONCAT_WS('|', CAST(dry_run_default AS STRING), CAST(dry_run_default AS STRING), CAST(dry_run_default AS STRING), CAST(dry_run_default AS STRING)),
          256
        ) AS record_hash,
        NULL AS metadata
      FROM miso_rtd_raw raw
      LEFT JOIN iso_registry reg
        ON upper(reg.iso) = 'MISO'
       AND upper(reg.location_id) = upper(CAST(dry_run_default AS STRING))
      WHERE dry_run_default IS NOT NULL
    """
  }
}

sink {
  Kafka {
    plugin_input = "miso_rtd_normalized"
    bootstrap.servers = "localhost:9092"
    topic = "dry_run_default"
    semantic = "AT_LEAST_ONCE"
    format = "avro"
    avro {
      use.schema.registry = true
      schema.registry.url = "http://localhost:8081"
      value.schema.subject = "dry_run_default"
      value.schema = """{"type":"record","name":"IsoLmpRecord","namespace":"aurum.iso","fields":[{"name":"iso_code","type":"string"}]}"""
    }
    producer {
      request.timeout.ms = 30000
      delivery.timeout.ms = 120000
      retry.backoff.max.ms = 10000
      retry.backoff.ms = 100
      acks = "all"
      enable.idempotence = true
      max.in.flight.requests.per.connection = 5
      linger.ms = 500
      batch.size = 32768
      retries = 5
    }
  }
}
