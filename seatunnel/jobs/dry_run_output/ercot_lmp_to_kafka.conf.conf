# ERCOT staged JSON â†’ Kafka (Avro)
#
# Required environment variables:
#   ERCOT_INPUT_JSON        - Path to JSON file containing normalized ERCOT LMP records (array of objects)
#   AURUM_KAFKA_BOOTSTRAP_SERVERS - Kafka brokers
#   AURUM_SCHEMA_REGISTRY_URL     - Schema Registry endpoint
#
# Optional environment variables:
#   ERCOT_TOPIC             - Kafka topic (default aurum.iso.ercot.lmp.v1)
#   ERCOT_SUBJECT           - Schema Registry subject (default <topic>-value)
#   ISO_LMP_SCHEMA          - Avro schema JSON populated by run_job.sh
#   ERCOT_CURRENCY          - Override currency code (default USD)
#   ERCOT_UOM               - Override unit of measure (default MWh)
#   ISO_LOCATION_REGISTRY   - Path to iso_nodes.csv (default config/iso_nodes.csv)

env {
  job.mode = "BATCH"
  parallelism = 1
}

source {
  LocalFile {
    path = "/tmp/ercot_test.json"
    format = "json"
    schema {
      fields {
        market = string
        delivery_date = string
        interval_start = string
        interval_end = string
        interval_minutes = string
        location_id = string
        location_name = string
        location_type = string
        price_total = string
        price_energy = string
        price_congestion = string
        price_loss = string
        currency = string
        uom = string
        settlement_point = string
        source_run_id = string
        ingest_ts = string
        record_hash = string
      }
    }
    jsonpath = "$[*]"
    result_table_name = "ercot_stage"
  }
  LocalFile {
    path = "dry_run_default"
    format = "csv"
    csv {
      delimiter = ","
      header = true
    }
    schema {
      fields {
        iso = string
        location_id = string
        location_name = string
        location_type = string
        zone = string
        hub = string
        timezone = string
      }
    }
    result_table_name = "iso_registry"
  }
}

transform {
  Sql {
    source_table_name = "ercot_stage"
    result_table_name = "ercot_normalized"
    query = """
      SELECT
        'ERCOT' AS iso_code,
        CASE
          WHEN upper(CAST(s.market AS STRING)) IN ('DA', 'DAM', 'DAY_AHEAD') THEN 'DAY_AHEAD'
          WHEN upper(CAST(s.market AS STRING)) IN ('RT', 'RTM', 'REAL_TIME') THEN 'REAL_TIME'
          ELSE COALESCE(UPPER(CAST(s.market AS STRING)), 'UNKNOWN')
        END AS market,
        CAST(s.delivery_date AS INT) AS delivery_date,
        CAST(s.interval_start AS BIGINT) AS interval_start,
        CASE
          WHEN s.interval_end IS NULL OR CAST(s.interval_end AS BIGINT) = 0 THEN NULL
          ELSE CAST(s.interval_end AS BIGINT)
        END AS interval_end,
        CAST(s.interval_minutes AS INT) AS interval_minutes,
        CAST(s.location_id AS STRING) AS location_id,
        COALESCE(reg.location_name, CAST(s.location_name AS STRING)) AS location_name,
        COALESCE(reg.location_type, COALESCE(UPPER(CAST(s.location_type AS STRING)), 'NODE')) AS location_type,
        reg.zone AS zone,
        reg.hub AS hub,
        reg.timezone AS timezone,
        CAST(s.price_total AS DOUBLE) AS price_total,
        CAST(s.price_energy AS DOUBLE) AS price_energy,
        CAST(s.price_congestion AS DOUBLE) AS price_congestion,
        CAST(s.price_loss AS DOUBLE) AS price_loss,
        COALESCE(CAST(s.currency AS STRING), 'dry_run_default') AS currency,
        COALESCE(CAST(s.uom AS STRING), 'dry_run_default') AS uom,
        CAST(s.settlement_point AS STRING) AS settlement_point,
        CAST(s.source_run_id AS STRING) AS source_run_id,
        COALESCE(CAST(s.ingest_ts AS BIGINT), CAST(UNIX_TIMESTAMP() * 1000000 AS BIGINT)) AS ingest_ts,
        CAST(s.record_hash AS STRING) AS record_hash,
        NULL AS metadata
      FROM ercot_stage s
      LEFT JOIN iso_registry reg
        ON upper(reg.iso) = 'ERCOT'
       AND upper(reg.location_id) = upper(CAST(s.location_id AS STRING))
    """
  }
}

sink {
  Kafka {
    plugin_input = "ercot_normalized"
    bootstrap.servers = "localhost:9092"
    topic = "dry_run_default"
    semantic = "AT_LEAST_ONCE"
    format = "avro"
    avro {
      use.schema.registry = true
      schema.registry.url = "http://localhost:8081"
      value.schema.subject = "dry_run_default"
      value.schema = """{"type":"record","name":"IsoLmpRecord","namespace":"aurum.iso","fields":[{"name":"iso_code","type":"string"}]}"""
    }
    producer {
      acks = "all"
      enable.idempotence = true
      max.in.flight.requests.per.connection = 5
      linger.ms = 500
      batch.size = 32768
      retries = 5
    }
  }
}
