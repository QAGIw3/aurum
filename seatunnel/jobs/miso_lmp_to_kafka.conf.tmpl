# MISO market reports (DA/RT) â†’ Kafka (Avro)
#
# Required environment variables:
#   MISO_URL                - HTTPS URL for the CSV report (see MISO Market Reports)
#   MISO_MARKET             - Market run (DAY_AHEAD or REAL_TIME)
#   KAFKA_BOOTSTRAP_SERVERS - Kafka brokers
#   SCHEMA_REGISTRY_URL     - Schema Registry endpoint
#
# Optional environment variables:
#   MISO_TOPIC              - Kafka topic (default aurum.iso.miso.lmp.v1)
#   MISO_SUBJECT            - Schema Registry subject (default <topic>-value)
#   ISO_LMP_SCHEMA          - Avro schema JSON populated by run_job.sh
#   MISO_TIME_FORMAT        - Java datetime pattern for parsing the timestamp column (default yyyy-MM-dd HH:mm:ss)
#   MISO_TIME_COLUMN        - Column containing the interval start timestamp (default Time)
#   MISO_NODE_COLUMN        - Column containing the node/settlement location (default CPNode)
#   MISO_NODE_ID_COLUMN     - Column containing the node id (default "CPNode ID")
#   MISO_LMP_COLUMN         - Column containing the total LMP (default LMP)
#   MISO_CONGESTION_COLUMN  - Column containing congestion (default MCC)
#   MISO_LOSS_COLUMN        - Column containing loss (default MLC)
#   MISO_INTERVAL_SECONDS   - Interval length in seconds (default 3600 for DA, 300 for RT)
#   MISO_CURRENCY           - Currency code (default USD)
#   MISO_UOM                - Price unit (default MWh)
#   ISO_LOCATION_REGISTRY   - Path to iso_nodes.csv (default config/iso_nodes.csv)
#
# SeaTunnel fetches the CSV, normalizes columns, and publishes Avro-encoded records.

env {
  job.mode = "BATCH"
  parallelism = 1
}

source {
  Http {
    url = "${MISO_URL}"
    method = "GET"
    connection_timeout_ms = 20000
    retry { interval_ms = 8000, max_retries = 10 }
    format = "csv"
    csv {
      delimiter = ","
      header = true
    }
    result_table_name = "miso_raw"
  }
  LocalFile {
    path = "${ISO_LOCATION_REGISTRY}"
    format = "csv"
    csv {
      delimiter = ","
      header = true
    }
    schema {
      fields {
        iso = string
        location_id = string
        location_name = string
        location_type = string
        zone = string
        hub = string
        timezone = string
      }
    }
    result_table_name = "iso_registry"
  }
}

transform {
  Sql {
    source_table_name = "miso_raw"
    result_table_name = "miso_normalized"
    query = """
      WITH enriched AS (
        SELECT
          `${MISO_TIME_COLUMN}` AS interval_ts,
          `${MISO_NODE_COLUMN}` AS location_name,
          `${MISO_NODE_ID_COLUMN}` AS location_id,
          `${MISO_LMP_COLUMN}` AS price_total_raw,
          `${MISO_CONGESTION_COLUMN}` AS price_congestion_raw,
          `${MISO_LOSS_COLUMN}` AS price_loss_raw
        FROM miso_raw
      )
      SELECT
        'MISO' AS iso_code,
        UPPER('${MISO_MARKET}') AS market,
        DATEDIFF(TO_DATE(e.interval_ts), TO_DATE('1970-01-01')) AS delivery_date,
        CAST(UNIX_TIMESTAMP(e.interval_ts, '${MISO_TIME_FORMAT}') * 1000000 AS BIGINT) AS interval_start,
        CAST(UNIX_TIMESTAMP(e.interval_ts, '${MISO_TIME_FORMAT}') * 1000000
             + ${MISO_INTERVAL_SECONDS} * 1000000 AS BIGINT) AS interval_end,
        ${MISO_INTERVAL_SECONDS} / 60 AS interval_minutes,
        CAST(e.location_id AS STRING) AS location_id,
        COALESCE(reg.location_name, CAST(e.location_name AS STRING)) AS location_name,
        COALESCE(reg.location_type, 'NODE') AS location_type,
        reg.zone AS zone,
        reg.hub AS hub,
        reg.timezone AS timezone,
        CAST(e.price_total_raw AS DOUBLE) AS price_total,
        CAST(e.price_total_raw AS DOUBLE)
          - COALESCE(CAST(e.price_congestion_raw AS DOUBLE), 0)
          - COALESCE(CAST(e.price_loss_raw AS DOUBLE), 0) AS price_energy,
        CAST(e.price_congestion_raw AS DOUBLE) AS price_congestion,
        CAST(e.price_loss_raw AS DOUBLE) AS price_loss,
        '${MISO_CURRENCY}' AS currency,
        '${MISO_UOM}' AS uom,
        CAST(e.location_name AS STRING) AS settlement_point,
        NULL AS source_run_id,
        CAST(UNIX_TIMESTAMP() * 1000000 AS BIGINT) AS ingest_ts,
        SHA2(CONCAT_WS('|', e.interval_ts, CAST(e.location_id AS STRING), CAST(e.price_total_raw AS STRING)), 256) AS record_hash,
        NULL AS metadata
      FROM enriched e
      LEFT JOIN iso_registry reg
        ON upper(reg.iso) = 'MISO'
       AND upper(reg.location_id) = upper(CAST(e.location_id AS STRING))
      WHERE e.interval_ts IS NOT NULL AND e.price_total_raw IS NOT NULL
    """
  }
}

sink {
  Kafka {
    plugin_input = "miso_normalized"
    bootstrap.servers = "${KAFKA_BOOTSTRAP_SERVERS}"
    topic = "${MISO_TOPIC}"
    semantic = "AT_LEAST_ONCE"
    format = "avro"
    avro {
      use.schema.registry = true
      schema.registry.url = "${SCHEMA_REGISTRY_URL}"
      value.schema.subject = "${MISO_SUBJECT}"
      value.schema = """${ISO_LMP_SCHEMA}"""
    }
    producer {
      acks = "all"
      enable.idempotence = true
      max.in.flight.requests.per.connection = 5
      linger.ms = 500
      batch.size = 32768
      retries = 5
    }
  }
}
